{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Working1]Copy_of_Keras2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaFAtu4G4gy_",
        "colab_type": "text"
      },
      "source": [
        "#**0**. Mounting Google **Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAw5rhCmQHot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnvF5FmY4twN",
        "colab_type": "text"
      },
      "source": [
        "#1. Importing Dataset & Mini-Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjHeolSW48w7",
        "colab_type": "text"
      },
      "source": [
        "**Importing `numpy`**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19NdnzyVHQYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6BV011i483j",
        "colab_type": "text"
      },
      "source": [
        "**Loading Dataset**\n",
        "\n",
        "Kindly change the path if required!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAv43KIeQoOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.load('/content/drive/My Drive/colab/ML AI Dataset/X_train.npy')\n",
        "Y = np.load('/content/drive/My Drive/colab/ML AI Dataset/Y_train.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg9Rc9NC5p_X",
        "colab_type": "text"
      },
      "source": [
        "## Mini Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DomWMgzO57gY",
        "colab_type": "text"
      },
      "source": [
        "Find the maximum value in **X** and normalize it. \n",
        "\n",
        "*(For images, it is sufficient to divide by 255, which is done later)*\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5FTsrfsQpon",
        "colab_type": "code",
        "outputId": "14ec01f7-91c5-4c5b-ebaf-e3b929ddc64a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.max(X[...,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho97pXZg6YRj",
        "colab_type": "text"
      },
      "source": [
        "**Checking thw distribution**\n",
        "\n",
        "It should be around 0.5 to make sure that we have good distribution of exammples, i.e, good distribution of 1's and 0's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWxwdDiEQrLX",
        "colab_type": "code",
        "outputId": "bdc290cb-8a28-46cc-bed3-e33288c87744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.mean(Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5016826923076924"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIQfTqQv603H",
        "colab_type": "text"
      },
      "source": [
        "Numbers of examples in the data..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v25_D-mQtgv",
        "colab_type": "code",
        "outputId": "5edf947d-a5a0-4d5c-80cb-bdb048e99ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "M = X.shape[0]\n",
        "M"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4160"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-vD7gYq67Jt",
        "colab_type": "text"
      },
      "source": [
        "Verifying the width/height of image..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM7rieGwQvq4",
        "colab_type": "code",
        "outputId": "dc82a973-20f7-4ff4-8d56-6f8f38f00771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAgAUDdn7FeC",
        "colab_type": "text"
      },
      "source": [
        "## Splitting dataset we have into training, validation and test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4jiwPhO78eH",
        "colab_type": "text"
      },
      "source": [
        "We will train on the Training set, validate it (to have an eye on overfitting/underfitting) using validation set and make a prediction using the test set made to check how well our model is performing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03ine1buQyvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shuffle = np.random.permutation(M)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlJGRRlX7dTa",
        "colab_type": "text"
      },
      "source": [
        "I have used a split of 85%-10%-5% (Training-Validation-Test) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz21CbdcQzvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X[:int(0.85*M),...]\n",
        "Y_train = Y[:int(0.85*M),...]\n",
        "Y_train = Y_train.reshape(Y_train.shape[0],1)\n",
        "\n",
        "X_val = X[int(0.85*M):int(0.95*M),...]\n",
        "Y_val = Y[int(0.85*M):int(0.95*M),...]\n",
        "Y_val = Y_val.reshape(Y_val.shape[0],1)\n",
        "\n",
        "X_test = X[int(0.95*M):,...]\n",
        "Y_test = Y[int(0.95*M):,...]\n",
        "Y_test = Y_test.reshape(Y_test.shape[0],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5ny951k7x3c",
        "colab_type": "text"
      },
      "source": [
        "Making sure that we have a good distribution of training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mbsu2CsQ4Ss",
        "colab_type": "code",
        "outputId": "611ca934-b666-4aab-d96a-a66517c304bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.mean(Y_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5016968325791855"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUbm9YBS8mX7",
        "colab_type": "text"
      },
      "source": [
        "The shape of training set obtained..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFSz2TkvQ6lG",
        "colab_type": "code",
        "outputId": "43adc3bb-3d9b-4698-a94a-597390cbddf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3536, 50, 50, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ho-CYMG8yfQ",
        "colab_type": "text"
      },
      "source": [
        "**Normalise the features!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDGdARVVQ-EE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train /= 255\n",
        "X_val /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PIZfhb8RDb3",
        "colab_type": "text"
      },
      "source": [
        "# 2. Building the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13XujHqb9Bty",
        "colab_type": "text"
      },
      "source": [
        "**Importing `keras` with Tensorflow backend**\n",
        "\n",
        "**Note:** The model is NOT Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vLziuFMQ__Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input,BatchNormalization, Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Flatten, Dropout, Dense, Concatenate, Add, UpSampling2D, LeakyReLU\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq8ktpQY9rIS",
        "colab_type": "text"
      },
      "source": [
        "**Data Augmentation**\n",
        "\n",
        "We have got very less training examples. So one way to reduce overfitting is to use Data Augmentation (so that our model can be feeded with some more variations of the training data, like flipping, rotating, zooming, etc. the original training data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUee6CX0RPoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "\t\trotation_range=12.5,\n",
        "\t\tzoom_range=0.13,\n",
        "\t\twidth_shift_range=0.12,\n",
        "\t\theight_shift_range=0.12,\n",
        "\t\thorizontal_flip=True,\n",
        "    vertical_flip = True,\n",
        "\t\tfill_mode=\"nearest\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT89M3ZtABu0",
        "colab_type": "text"
      },
      "source": [
        "**Model**\n",
        "\n",
        "I have used a simple Model, whose schema is given below:\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "**[INPUT]**\n",
        "\n",
        "---\n",
        "\n",
        "**[Convolution]** *size=(3,3) filters=32 stride=None padding=Same*\n",
        "\n",
        "**[Batch Normalization]** *Along last axis*\n",
        "\n",
        "**[Activation]** *function=relu*\n",
        "\n",
        "**[Dropout]** *factor=0.5*\n",
        "\n",
        "**[Convolution]** *size=(3,3) filters=32 stride=None padding=Valid*\n",
        "\n",
        "**[Batch Normalization]** *Along last axis*\n",
        "\n",
        "**[Activation]** *function=relu*\n",
        "\n",
        "**[Dropout]** *factor=0.5*\n",
        "\n",
        "**[Max Pooling]** *size=(2,2)*   --- (A)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**[Convolution]** *size=(3,3) filters=64 stride=None padding=Same*\n",
        "\n",
        "**[Batch Normalization]** *Along last axis*\n",
        "\n",
        "**[Activation]** *function=relu*\n",
        "\n",
        "**[Dropout]** *factor=0.3*\n",
        "\n",
        "\n",
        "**[(Seperable) Convolution]** *size=(3,3) filters=64 stride=None padding=Same*\n",
        "\n",
        "**[Batch Normalization]** *Along last axis*\n",
        "\n",
        "**[Activation]** *function=leaky_relu* --(X1)\n",
        "\n",
        "**[Convolution]** *size=(3,3) filters=64 stride=None padding=Same*\n",
        "\n",
        "**[Batch Normalization]** *Along last axis*  --(Y1)\n",
        "\n",
        "**[Add]** (X1+Y1)\n",
        "\n",
        "**[Activation]** *function=leaky_relu*\n",
        "\n",
        "**[Dropout]** *factor=0.3*\n",
        "\n",
        "**[Max Pooling]** *size=(2,2)*   --- (B)\n",
        "\n",
        "---\n",
        "\n",
        "**[Convolution]** *size=(3,3) filters=128 stride=None padding=Same*\n",
        "\n",
        "**[Batch Normalization]** *Along last axis*\n",
        "\n",
        "**[Activation]** *function=relu*\n",
        "\n",
        "\n",
        "\n",
        "**[(Seperable) Convolution]** *size=(3,3) filters=128 stride=None padding=Same*\n",
        "\n",
        "**[Batch Normalization]** *Along last axis*\n",
        "\n",
        "**[Activation]** *function=leaky_relu* --(X1)\n",
        "\n",
        "**[Convolution]** *size=(3,3) filters=128 stride=None padding=Same*\n",
        "\n",
        "**[Batch Normalization]** *Along last axis*  --(Y1)\n",
        "\n",
        "**[Add]** (X1+Y1)\n",
        "\n",
        "**[Activation]** *function=leaky_relu*\n",
        "\n",
        "**[Dropout]** *factor=0.25*\n",
        "\n",
        "**[Max Pooling]** *size=(2,2)*   --- (C)\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "**[Up Sampling]**(A) *size=(2,2)*  --- (A')\n",
        "\n",
        "**[Up Sampling]**(B) *size=(4,4)*  --- (B')\n",
        "\n",
        "**[Up Sampling]**(C) *size=(8,8)*  --- (C')\n",
        "\n",
        "---\n",
        "\n",
        "**[Concatenate]** (A',B',C')\n",
        "\n",
        "---\n",
        "\n",
        "**[Global Average Pooling2D]**\n",
        "\n",
        "**[Dense (Fully connected)]** *num_units=128,activation='relu'*\n",
        "\n",
        "**[Dropout]** *factor=0.45*\n",
        "\n",
        "**[Dense (Fully connected)]** *num_units=32,activation='relu'*\n",
        "\n",
        "**[Dropout]** *factor=0.35*\n",
        "\n",
        "**[Dense (Fully connected)]** *num_units=1,activation='sigmoid'*\n",
        "\n",
        "---\n",
        "\n",
        "**[OUTPUT]**\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH1S4ylVJXz_",
        "colab_type": "text"
      },
      "source": [
        "**Problems at Hand**\n",
        "\n",
        "\n",
        "*   Going deeper can increase overfitting\n",
        "*   Increasing number of hidden units can increase overfitting\n",
        "*   Dropout is used to reduce overfitting and the values were tuned while training the model to get good results\n",
        "*   Regularization was an option but didn't increase the results significantly. So it was dropped\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ux1_G48KUGc",
        "colab_type": "text"
      },
      "source": [
        "***References***\n",
        "\n",
        "\n",
        "*  Inspiration for 'adding' layers (Residual Layer) was from ResNet paper titled \n",
        "[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) *by Kaiming He et al.*,2015\n",
        "\n",
        "*The layers were tuned based on the results with time.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMMIXrOsRdXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = Input(shape=X_train.shape[1:])\n",
        "\n",
        "x = Conv2D(filters=32, kernel_size=(3, 3), activation='linear', padding=\"same\")(inp)\n",
        "x = BatchNormalization(axis=-1)(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Conv2D(filters=32, kernel_size=(3, 3), activation='linear', padding=\"valid\")(x)\n",
        "x = BatchNormalization(axis=-1)(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x1 = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "x = Conv2D(filters=64, kernel_size=(3, 3), activation='linear', padding=\"same\")(x1)\n",
        "x = BatchNormalization(axis=-1)(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "y = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='linear', padding=\"same\")(x)\n",
        "y = BatchNormalization(axis=-1)(y)\n",
        "y = LeakyReLU()(y)\n",
        "\n",
        "x = Conv2D(filters=64, kernel_size=(3, 3), activation='linear', padding=\"same\")(y)\n",
        "x = BatchNormalization(axis=-1)(x)\n",
        "x = Add()([x,y])\n",
        "\n",
        "x = LeakyReLU()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x2 = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "\n",
        "x = Conv2D(filters=128, kernel_size=(3, 3), activation='linear', padding=\"same\")(x2)\n",
        "x = BatchNormalization(axis=-1)(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "y = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='linear', padding=\"same\")(x)\n",
        "y = BatchNormalization(axis=-1)(y)\n",
        "y = LeakyReLU()(y)\n",
        "\n",
        "x = Conv2D(filters=128, kernel_size=(3, 3), activation='linear', padding=\"same\")(y)\n",
        "x = BatchNormalization(axis=-1)(x)\n",
        "x = Add()([x,y])\n",
        "\n",
        "x = LeakyReLU()(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "x3 = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "\n",
        "x1 = UpSampling2D(size=(2, 2))(x1)\n",
        "x2 = UpSampling2D(size=(4, 4))(x2)\n",
        "x3 = UpSampling2D(size=(8, 8))(x3)\n",
        "\n",
        "x = Concatenate()([x1,x2,x3])\n",
        "# x = Concatenate()([x1,x2])\n",
        "\n",
        "x= GlobalAveragePooling2D()(x)\n",
        "# x = Flatten()(x)\n",
        "x = Dense(128,activation='relu')(x)\n",
        "x = Dropout(0.45)(x)\n",
        "x = Dense(32,activation='relu')(x)\n",
        "x = Dropout(0.35)(x)\n",
        "x = Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=inp,outputs=x)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv0JaApba2dT",
        "colab_type": "code",
        "outputId": "ad95af97-7ca1-4595-e637-91805c854be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer='adam',metrics=[\"accuracy\"])\n",
        "history = model.fit_generator(\n",
        "\taug.flow(X_train, Y_train, batch_size=16),\n",
        "\tvalidation_data=(X_val, Y_val),\n",
        "\tepochs=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/128\n",
            "221/221 [==============================] - 9s 42ms/step - loss: 0.6202 - accuracy: 0.7048 - val_loss: 0.6373 - val_accuracy: 0.7163\n",
            "Epoch 2/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.5694 - accuracy: 0.7325 - val_loss: 0.6513 - val_accuracy: 0.5337\n",
            "Epoch 3/128\n",
            "221/221 [==============================] - 7s 32ms/step - loss: 0.5598 - accuracy: 0.7443 - val_loss: 0.6137 - val_accuracy: 0.6731\n",
            "Epoch 4/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.5501 - accuracy: 0.7528 - val_loss: 0.7045 - val_accuracy: 0.5312\n",
            "Epoch 5/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.5312 - accuracy: 0.7537 - val_loss: 0.6688 - val_accuracy: 0.5264\n",
            "Epoch 6/128\n",
            "221/221 [==============================] - 7s 32ms/step - loss: 0.5408 - accuracy: 0.7571 - val_loss: 0.6226 - val_accuracy: 0.6514\n",
            "Epoch 7/128\n",
            "221/221 [==============================] - 7s 32ms/step - loss: 0.5253 - accuracy: 0.7644 - val_loss: 0.6074 - val_accuracy: 0.6659\n",
            "Epoch 8/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.5209 - accuracy: 0.7656 - val_loss: 0.5290 - val_accuracy: 0.7548\n",
            "Epoch 9/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.5168 - accuracy: 0.7661 - val_loss: 0.5761 - val_accuracy: 0.6923\n",
            "Epoch 10/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.5151 - accuracy: 0.7763 - val_loss: 0.5863 - val_accuracy: 0.6779\n",
            "Epoch 11/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.5147 - accuracy: 0.7732 - val_loss: 0.6440 - val_accuracy: 0.6394\n",
            "Epoch 12/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.5089 - accuracy: 0.7687 - val_loss: 0.6909 - val_accuracy: 0.6154\n",
            "Epoch 13/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.5080 - accuracy: 0.7695 - val_loss: 0.5953 - val_accuracy: 0.7019\n",
            "Epoch 14/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.5036 - accuracy: 0.7653 - val_loss: 1.3124 - val_accuracy: 0.5096\n",
            "Epoch 15/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.5038 - accuracy: 0.7661 - val_loss: 0.5679 - val_accuracy: 0.7620\n",
            "Epoch 16/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4992 - accuracy: 0.7704 - val_loss: 1.5000 - val_accuracy: 0.4976\n",
            "Epoch 17/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4976 - accuracy: 0.7673 - val_loss: 0.7281 - val_accuracy: 0.6394\n",
            "Epoch 18/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4982 - accuracy: 0.7684 - val_loss: 0.6337 - val_accuracy: 0.6659\n",
            "Epoch 19/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4899 - accuracy: 0.7726 - val_loss: 0.5597 - val_accuracy: 0.7668\n",
            "Epoch 20/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4947 - accuracy: 0.7822 - val_loss: 0.5705 - val_accuracy: 0.7620\n",
            "Epoch 21/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4854 - accuracy: 0.7800 - val_loss: 0.6243 - val_accuracy: 0.6154\n",
            "Epoch 22/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4923 - accuracy: 0.7822 - val_loss: 1.0321 - val_accuracy: 0.5240\n",
            "Epoch 23/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4913 - accuracy: 0.7811 - val_loss: 0.5522 - val_accuracy: 0.7596\n",
            "Epoch 24/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4823 - accuracy: 0.7811 - val_loss: 0.5071 - val_accuracy: 0.7788\n",
            "Epoch 25/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4801 - accuracy: 0.7794 - val_loss: 0.5630 - val_accuracy: 0.7188\n",
            "Epoch 26/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4835 - accuracy: 0.7831 - val_loss: 0.5532 - val_accuracy: 0.7404\n",
            "Epoch 27/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4782 - accuracy: 0.7814 - val_loss: 0.5261 - val_accuracy: 0.7812\n",
            "Epoch 28/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4817 - accuracy: 0.7825 - val_loss: 0.6056 - val_accuracy: 0.6899\n",
            "Epoch 29/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4817 - accuracy: 0.7913 - val_loss: 0.5359 - val_accuracy: 0.7452\n",
            "Epoch 30/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4793 - accuracy: 0.7865 - val_loss: 0.5373 - val_accuracy: 0.7692\n",
            "Epoch 31/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4775 - accuracy: 0.7890 - val_loss: 0.5994 - val_accuracy: 0.6899\n",
            "Epoch 32/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4750 - accuracy: 0.7831 - val_loss: 0.5598 - val_accuracy: 0.7236\n",
            "Epoch 33/128\n",
            "221/221 [==============================] - 7s 32ms/step - loss: 0.4709 - accuracy: 0.7944 - val_loss: 0.9007 - val_accuracy: 0.5745\n",
            "Epoch 34/128\n",
            "221/221 [==============================] - 7s 32ms/step - loss: 0.4700 - accuracy: 0.7879 - val_loss: 0.5162 - val_accuracy: 0.7764\n",
            "Epoch 35/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4612 - accuracy: 0.7936 - val_loss: 0.5570 - val_accuracy: 0.7163\n",
            "Epoch 36/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4709 - accuracy: 0.7924 - val_loss: 0.5653 - val_accuracy: 0.7548\n",
            "Epoch 37/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4618 - accuracy: 0.7941 - val_loss: 0.7067 - val_accuracy: 0.6635\n",
            "Epoch 38/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4739 - accuracy: 0.7845 - val_loss: 0.5642 - val_accuracy: 0.7236\n",
            "Epoch 39/128\n",
            "221/221 [==============================] - 7s 32ms/step - loss: 0.4636 - accuracy: 0.7885 - val_loss: 0.5551 - val_accuracy: 0.7115\n",
            "Epoch 40/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4628 - accuracy: 0.7921 - val_loss: 0.5526 - val_accuracy: 0.7308\n",
            "Epoch 41/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4601 - accuracy: 0.7910 - val_loss: 0.5556 - val_accuracy: 0.7188\n",
            "Epoch 42/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4558 - accuracy: 0.7904 - val_loss: 0.8342 - val_accuracy: 0.6346\n",
            "Epoch 43/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4693 - accuracy: 0.7938 - val_loss: 0.5263 - val_accuracy: 0.7476\n",
            "Epoch 44/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4600 - accuracy: 0.7967 - val_loss: 0.5048 - val_accuracy: 0.7332\n",
            "Epoch 45/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4543 - accuracy: 0.7964 - val_loss: 0.5082 - val_accuracy: 0.7620\n",
            "Epoch 46/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4464 - accuracy: 0.8054 - val_loss: 0.4964 - val_accuracy: 0.7644\n",
            "Epoch 47/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4539 - accuracy: 0.8012 - val_loss: 0.4853 - val_accuracy: 0.7740\n",
            "Epoch 48/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4553 - accuracy: 0.7936 - val_loss: 0.4772 - val_accuracy: 0.7692\n",
            "Epoch 49/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4535 - accuracy: 0.8026 - val_loss: 0.5028 - val_accuracy: 0.7524\n",
            "Epoch 50/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4416 - accuracy: 0.7998 - val_loss: 0.5685 - val_accuracy: 0.6995\n",
            "Epoch 51/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4548 - accuracy: 0.7986 - val_loss: 0.5794 - val_accuracy: 0.7163\n",
            "Epoch 52/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4472 - accuracy: 0.8043 - val_loss: 0.6195 - val_accuracy: 0.7139\n",
            "Epoch 53/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4530 - accuracy: 0.8018 - val_loss: 0.4937 - val_accuracy: 0.7692\n",
            "Epoch 54/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4441 - accuracy: 0.7961 - val_loss: 0.7039 - val_accuracy: 0.6875\n",
            "Epoch 55/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4372 - accuracy: 0.8102 - val_loss: 0.5888 - val_accuracy: 0.7019\n",
            "Epoch 56/128\n",
            "221/221 [==============================] - 7s 32ms/step - loss: 0.4427 - accuracy: 0.8108 - val_loss: 0.5735 - val_accuracy: 0.7236\n",
            "Epoch 57/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4471 - accuracy: 0.7998 - val_loss: 0.4759 - val_accuracy: 0.7740\n",
            "Epoch 58/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4399 - accuracy: 0.8029 - val_loss: 0.5100 - val_accuracy: 0.7452\n",
            "Epoch 59/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4459 - accuracy: 0.8071 - val_loss: 0.4813 - val_accuracy: 0.7861\n",
            "Epoch 60/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4490 - accuracy: 0.8009 - val_loss: 0.4815 - val_accuracy: 0.7716\n",
            "Epoch 61/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4398 - accuracy: 0.8083 - val_loss: 0.4665 - val_accuracy: 0.7740\n",
            "Epoch 62/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4378 - accuracy: 0.8074 - val_loss: 0.5088 - val_accuracy: 0.7380\n",
            "Epoch 63/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4483 - accuracy: 0.8003 - val_loss: 0.6575 - val_accuracy: 0.5865\n",
            "Epoch 64/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4443 - accuracy: 0.8060 - val_loss: 0.4761 - val_accuracy: 0.7861\n",
            "Epoch 65/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4323 - accuracy: 0.8094 - val_loss: 0.5009 - val_accuracy: 0.7572\n",
            "Epoch 66/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4313 - accuracy: 0.8108 - val_loss: 0.6002 - val_accuracy: 0.6418\n",
            "Epoch 67/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4389 - accuracy: 0.8057 - val_loss: 0.5145 - val_accuracy: 0.7212\n",
            "Epoch 68/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4275 - accuracy: 0.8170 - val_loss: 0.4865 - val_accuracy: 0.7620\n",
            "Epoch 69/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4235 - accuracy: 0.8128 - val_loss: 0.6435 - val_accuracy: 0.7163\n",
            "Epoch 70/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4346 - accuracy: 0.8051 - val_loss: 0.4827 - val_accuracy: 0.7861\n",
            "Epoch 71/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4361 - accuracy: 0.8088 - val_loss: 0.5777 - val_accuracy: 0.7524\n",
            "Epoch 72/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4359 - accuracy: 0.8043 - val_loss: 0.5055 - val_accuracy: 0.7548\n",
            "Epoch 73/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4342 - accuracy: 0.8071 - val_loss: 0.5280 - val_accuracy: 0.7428\n",
            "Epoch 74/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4309 - accuracy: 0.8128 - val_loss: 0.5124 - val_accuracy: 0.7452\n",
            "Epoch 75/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4300 - accuracy: 0.8122 - val_loss: 0.5184 - val_accuracy: 0.7380\n",
            "Epoch 76/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4282 - accuracy: 0.8196 - val_loss: 0.5836 - val_accuracy: 0.6731\n",
            "Epoch 77/128\n",
            "221/221 [==============================] - 7s 34ms/step - loss: 0.4335 - accuracy: 0.8049 - val_loss: 0.9076 - val_accuracy: 0.6947\n",
            "Epoch 78/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4204 - accuracy: 0.8159 - val_loss: 0.4493 - val_accuracy: 0.7909\n",
            "Epoch 79/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4253 - accuracy: 0.8114 - val_loss: 0.5519 - val_accuracy: 0.7332\n",
            "Epoch 80/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4210 - accuracy: 0.8128 - val_loss: 0.4488 - val_accuracy: 0.7812\n",
            "Epoch 81/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4212 - accuracy: 0.8085 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 82/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4193 - accuracy: 0.8105 - val_loss: 0.4945 - val_accuracy: 0.7692\n",
            "Epoch 83/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4229 - accuracy: 0.8114 - val_loss: 0.4469 - val_accuracy: 0.8053\n",
            "Epoch 84/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4239 - accuracy: 0.8097 - val_loss: 0.4654 - val_accuracy: 0.7668\n",
            "Epoch 85/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4157 - accuracy: 0.8128 - val_loss: 0.4817 - val_accuracy: 0.7837\n",
            "Epoch 86/128\n",
            "221/221 [==============================] - 7s 32ms/step - loss: 0.4213 - accuracy: 0.8091 - val_loss: 0.5700 - val_accuracy: 0.6923\n",
            "Epoch 87/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4231 - accuracy: 0.8091 - val_loss: 0.5985 - val_accuracy: 0.6418\n",
            "Epoch 88/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4110 - accuracy: 0.8145 - val_loss: 0.5153 - val_accuracy: 0.7260\n",
            "Epoch 89/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4259 - accuracy: 0.8100 - val_loss: 0.5505 - val_accuracy: 0.7404\n",
            "Epoch 90/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4234 - accuracy: 0.8111 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
            "Epoch 91/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4183 - accuracy: 0.8083 - val_loss: 0.4779 - val_accuracy: 0.7909\n",
            "Epoch 92/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4209 - accuracy: 0.8108 - val_loss: 0.5391 - val_accuracy: 0.7212\n",
            "Epoch 93/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4236 - accuracy: 0.8184 - val_loss: 0.4629 - val_accuracy: 0.7885\n",
            "Epoch 94/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4182 - accuracy: 0.8111 - val_loss: 0.4680 - val_accuracy: 0.8029\n",
            "Epoch 95/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4203 - accuracy: 0.8102 - val_loss: 0.4714 - val_accuracy: 0.7837\n",
            "Epoch 96/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4160 - accuracy: 0.8232 - val_loss: 0.5064 - val_accuracy: 0.7740\n",
            "Epoch 97/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4214 - accuracy: 0.8167 - val_loss: 0.4525 - val_accuracy: 0.7981\n",
            "Epoch 98/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4233 - accuracy: 0.8122 - val_loss: 0.7490 - val_accuracy: 0.7043\n",
            "Epoch 99/128\n",
            "221/221 [==============================] - 7s 32ms/step - loss: 0.4129 - accuracy: 0.8204 - val_loss: 0.5115 - val_accuracy: 0.7380\n",
            "Epoch 100/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4136 - accuracy: 0.8199 - val_loss: 0.4664 - val_accuracy: 0.7885\n",
            "Epoch 101/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4043 - accuracy: 0.8238 - val_loss: 0.7103 - val_accuracy: 0.7332\n",
            "Epoch 102/128\n",
            "221/221 [==============================] - 7s 32ms/step - loss: 0.4140 - accuracy: 0.8114 - val_loss: 0.4589 - val_accuracy: 0.7885\n",
            "Epoch 103/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4042 - accuracy: 0.8247 - val_loss: 0.6739 - val_accuracy: 0.7332\n",
            "Epoch 104/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4091 - accuracy: 0.8083 - val_loss: 0.4709 - val_accuracy: 0.7740\n",
            "Epoch 105/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4070 - accuracy: 0.8218 - val_loss: 0.5281 - val_accuracy: 0.7620\n",
            "Epoch 106/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4008 - accuracy: 0.8221 - val_loss: 0.6197 - val_accuracy: 0.7572\n",
            "Epoch 107/128\n",
            "221/221 [==============================] - 7s 32ms/step - loss: 0.4173 - accuracy: 0.8139 - val_loss: 0.4670 - val_accuracy: 0.7716\n",
            "Epoch 108/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4100 - accuracy: 0.8238 - val_loss: 0.4473 - val_accuracy: 0.8125\n",
            "Epoch 109/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4055 - accuracy: 0.8201 - val_loss: 0.4477 - val_accuracy: 0.8005\n",
            "Epoch 110/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4127 - accuracy: 0.8210 - val_loss: 0.5109 - val_accuracy: 0.7260\n",
            "Epoch 111/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4104 - accuracy: 0.8213 - val_loss: 0.5004 - val_accuracy: 0.7476\n",
            "Epoch 112/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4036 - accuracy: 0.8244 - val_loss: 0.5086 - val_accuracy: 0.7692\n",
            "Epoch 113/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4034 - accuracy: 0.8281 - val_loss: 0.4693 - val_accuracy: 0.7548\n",
            "Epoch 114/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.3959 - accuracy: 0.8232 - val_loss: 0.6308 - val_accuracy: 0.7404\n",
            "Epoch 115/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4032 - accuracy: 0.8249 - val_loss: 0.4651 - val_accuracy: 0.7909\n",
            "Epoch 116/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4029 - accuracy: 0.8227 - val_loss: 0.6633 - val_accuracy: 0.7476\n",
            "Epoch 117/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4040 - accuracy: 0.8193 - val_loss: 0.4557 - val_accuracy: 0.7861\n",
            "Epoch 118/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.3996 - accuracy: 0.8179 - val_loss: 0.4602 - val_accuracy: 0.7933\n",
            "Epoch 119/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4012 - accuracy: 0.8193 - val_loss: 0.5465 - val_accuracy: 0.7740\n",
            "Epoch 120/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.3976 - accuracy: 0.8249 - val_loss: 0.5193 - val_accuracy: 0.7716\n",
            "Epoch 121/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4039 - accuracy: 0.8252 - val_loss: 0.5740 - val_accuracy: 0.6755\n",
            "Epoch 122/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.3935 - accuracy: 0.8235 - val_loss: 0.5374 - val_accuracy: 0.7861\n",
            "Epoch 123/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4124 - accuracy: 0.8170 - val_loss: 1.4787 - val_accuracy: 0.6058\n",
            "Epoch 124/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.3964 - accuracy: 0.8252 - val_loss: 0.4974 - val_accuracy: 0.7644\n",
            "Epoch 125/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4116 - accuracy: 0.8150 - val_loss: 0.4562 - val_accuracy: 0.7909\n",
            "Epoch 126/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4013 - accuracy: 0.8258 - val_loss: 0.4540 - val_accuracy: 0.7885\n",
            "Epoch 127/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.3876 - accuracy: 0.8306 - val_loss: 0.8055 - val_accuracy: 0.7404\n",
            "Epoch 128/128\n",
            "221/221 [==============================] - 7s 33ms/step - loss: 0.4013 - accuracy: 0.8187 - val_loss: 0.4792 - val_accuracy: 0.7957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7JYOZhHcWAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Without data augmentation\n",
        "# model.compile(loss=\"binary_crossentropy\", optimizer='adam',metrics=[\"accuracy\"])\n",
        "# model.fit(X_train,Y_train,validation_data=(X_val,Y_val),epochs=64,batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecyFwj4zNoh9",
        "colab_type": "text"
      },
      "source": [
        "The training is done... Let's run it on the test data to see how this model performs on unseen examples.\n",
        "\n",
        "**Note:** Retraining the model might not give the same result due to randomness, like in Data Augmentation. The model was trained several times (iterated several times) to get this accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpZuZggWe5d2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans =model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBHWLKD5Pb3O",
        "colab_type": "text"
      },
      "source": [
        "Calculating the accuracy..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSuj39b3be1o",
        "colab_type": "code",
        "outputId": "7abdcbe9-8f28-4ea3-feed-252fde9fa604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ans = ans.round()\n",
        "np.mean((ans==Y_test).astype('int'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7836538461538461"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6zkroI7Pl_F",
        "colab_type": "text"
      },
      "source": [
        "Let's calculate the Precision, Recall and F1 score using the `sklearn` inbuilt functions *(and this code was copied from internet)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8aSdC8EbiuI",
        "colab_type": "code",
        "outputId": "c583a7e8-3b1e-475a-d8dc-babb278b47db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "\n",
        "y_test = Y_test\n",
        "y_pred = ans\n",
        "\n",
        "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(recall_score(y_test, y_pred, average=\"macro\"))   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7538461538461538\n",
            "0.7713133640552995\n",
            "0.7624686542212316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXV9EwNRPAOb",
        "colab_type": "text"
      },
      "source": [
        "Save the model for using it in the future...\n",
        "\n",
        "**Note:** Change the path if required..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Piw22GBV7xT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/colab/cancer.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PO3VXLMOT77",
        "colab_type": "text"
      },
      "source": [
        "And the summary (info on paramters) of the model... *(didn't run it)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ8wiZLnV5ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f12RGRlfOl-K",
        "colab_type": "text"
      },
      "source": [
        "# 3. Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHGjDyIAOm3Q",
        "colab_type": "text"
      },
      "source": [
        "Loading the saved model.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYf-CLRPUAAt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3cc4666-0665-48ac-9063-9ad2f1ed6545"
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7xZ02HHUQhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('/content/drive/My Drive/colab/cancer.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaAbHIFJOmwt",
        "colab_type": "text"
      },
      "source": [
        "Import the test data set **and normalise**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBQvcE6IU5-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = np.load('/content/drive/My Drive/colab/ML AI Dataset/X_test.npy')\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYYh6vzuWxN6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ffadb21-338f-4e92-d67b-502f61414386"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1387, 50, 50, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMcNwaoykhfy",
        "colab_type": "text"
      },
      "source": [
        "It's time to predict **and round the floating value to 0 or 1**!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdVKPDBWW72A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM_t_fC6aFz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = np.round(ans)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XkUEXKZXCY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d5dea93-a5bf-480b-eb41-0f1a57113e41"
      },
      "source": [
        "ans.mean()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5638068"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz4g6HggkwQL",
        "colab_type": "text"
      },
      "source": [
        "**Save the prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umTPR3H-kzow",
        "colab_type": "text"
      },
      "source": [
        "*  In `.npy` format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8MB-8LyXGHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('/content/drive/My Drive/colab/Y_out.npy',ans)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RKS1oKAk9dO",
        "colab_type": "text"
      },
      "source": [
        "*  In `.csv` format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQdZ42HiZ-8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt('/content/drive/My Drive/colab/subhalingam_d.csv', [ans[:,0]], delimiter='\\n', fmt='%d' , header='Output')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWefBpoGlJU6",
        "colab_type": "text"
      },
      "source": [
        "Having a look at the prediction..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyfab_wNXTJ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c6496f4-9312-4ed0-97a0-29e75c920b76"
      },
      "source": [
        "ans[:,0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., ..., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}